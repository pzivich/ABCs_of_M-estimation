{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72767b9",
   "metadata": {},
   "source": [
    "# ABC's of M-estimation\n",
    "\n",
    "Code for applied examples (Section 2)\n",
    "\n",
    "Paul Zivich (2024/06/10)\n",
    "\n",
    "## Loading dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ebf7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versions\n",
      "NumPy:         1.25.2\n",
      "Pandas:        1.4.1\n",
      "SciPy:         1.11.2\n",
      "Statsmodels:   0.14.1\n",
      "Delicatessen:  2.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.optimize import root\n",
    "from scipy.optimize import approx_fprime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import delicatessen as deli\n",
    "from delicatessen import MEstimator\n",
    "from delicatessen.estimating_equations import ee_regression\n",
    "from delicatessen.utilities import inverse_logit\n",
    "\n",
    "\n",
    "print(\"versions\")\n",
    "print('NumPy:        ', np.__version__)\n",
    "print('Pandas:       ', pd.__version__)\n",
    "print('SciPy:        ', sp.__version__)\n",
    "print('Statsmodels:  ', sm.__version__)\n",
    "print('Delicatessen: ', deli.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637bb4c2",
   "metadata": {},
   "source": [
    "## Example 1: Logistic Regression\n",
    "\n",
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac7d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame()\n",
    "d['X'] = [0, 0, 0, 0, 1, 1, 1, 1]\n",
    "d['W'] = [0, 0, 1, 1, 0, 0, 1, 1]\n",
    "d['Y'] = [0, 1, 0, 1, 0, 1, 0, 1]\n",
    "d['n'] = [496, 74, 113, 25, 85, 15, 15, 3]\n",
    "d['intercept'] = 1\n",
    "d = pd.DataFrame(np.repeat(d.values, d['n'], axis=0),   # Expanding compact data frame\n",
    "                 columns=d.columns)                     # ... keeping column names\n",
    "d = d[['intercept', 'X', 'W', 'Y']].copy()              # Dropping the n column\n",
    "n = d.shape[0]                                          # Number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d6f57",
   "metadata": {},
   "source": [
    "### Regression by MLE\n",
    "\n",
    "Using `statsmodels` GLM functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b112c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "fam = sm.families.Binomial()           # Binomial family\n",
    "mle = smf.glm(\"Y ~ X + W\",             # GLM with formula\n",
    "              data=d,                  # ... for loaded data\n",
    "              family=fam               # ... logistic model\n",
    "              ).fit()                  # ... then fitting model\n",
    "beta_mle = np.asarray(mle.params)      # Extracting beta parameters\n",
    "sigma_mle = np.asarray(mle.bse**2)     # Extracting variance estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f5174b",
   "metadata": {},
   "source": [
    "### M-estimator by-hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b476c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimating_functions(theta):\n",
    "    # Calculating predicted probability of Y\n",
    "    yhat = inverse_logit(theta[0]*1 + theta[1]*d['X'] + theta[2]*d['W'])\n",
    "\n",
    "    # Calculating the residual (observed Y minus predicted Y)\n",
    "    residual = d['Y'] - yhat\n",
    "\n",
    "    # Calculating the corresponding score functions\n",
    "    score = [residual*1,         # Score for intercept\n",
    "             residual*d['X'],    # Score for X\n",
    "             residual*d['W']]    # Score for W\n",
    "\n",
    "    # Returning scores as a NumPy array\n",
    "    return np.asarray(score)\n",
    "\n",
    "\n",
    "def estimating_equations(theta):\n",
    "    ef = estimating_functions(theta=theta)\n",
    "    vals = ()                    # Create empty tuple\n",
    "    rows = ef.shape[0]           # Determine how many rows / parameters are present\n",
    "    for i in range(rows):        # Go through each individual theta in the stack\n",
    "        row = ef[i, :]           # ... extract corresponding row\n",
    "        vals += (np.sum(row), )  # ... then add the theta sum to the tuple of thetas\n",
    "    # Return evaluated estimating equations\n",
    "    return np.asarray(vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d432e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root-finding\n",
    "proc = root(estimating_equations,       # Function to find root(s) of\n",
    "            x0=np.array([0, 0, 0, ]),   # ... starting values for root-finding procedure\n",
    "            method='lm')                # ... algorithm to use (Levenberg-Marquardt here)\n",
    "beta_mest = proc.x                      # Extract beta parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74d0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baking the bread (approximate derivative)\n",
    "deriv = approx_fprime(xk=beta_mest,             # Approximating partial derivatives at beta\n",
    "                      f=estimating_equations,   # ... of the estimating equations\n",
    "                      epsilon=1e-9)             # ... with specified deviation from point\n",
    "bread = -1*deriv / n                            # Creating bread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4694dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooking the filling (matrix algebra)\n",
    "filling = np.dot(estimating_functions(beta_mest),\n",
    "                 estimating_functions(beta_mest).T)\n",
    "filling = filling / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8f1d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling the sandwich (matrix algebra)\n",
    "bread_invert = np.linalg.inv(bread)\n",
    "sandwich = np.dot(np.dot(bread_invert, filling),\n",
    "                  bread_invert.T) / n\n",
    "sigma_mest = np.diag(sandwich)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ae2d1",
   "metadata": {},
   "source": [
    "### Using `delicatessen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d631e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(theta):\n",
    "    # Using built-in regression model functionality from delicatessen\n",
    "    return ee_regression(theta=theta,\n",
    "                         y=d['Y'],\n",
    "                         X=d[['intercept', 'X', 'W']],\n",
    "                         model='logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eef896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mestr = MEstimator(psi, init=[0, 0, 0])\n",
    "mestr.estimate(solver='lm')\n",
    "\n",
    "beta_deli = mestr.theta\n",
    "sigma_deli = np.diag(mestr.variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5617c86c",
   "metadata": {},
   "source": [
    "### Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb4e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Logistic Regression\n",
      "Point Estimates\n",
      "MLE:          [-1.89450082  0.11873535  0.36051133]\n",
      "By-hand:      [-1.89450082  0.11873535  0.36051133]\n",
      "Delicatessen: [-1.89450082  0.11873535  0.36051133]\n",
      "Variance Estimates\n",
      "MLE:          [0.01496046 0.07764837 0.05660453]\n",
      "By-hand:      [0.01484041 0.0777204  0.05652963]\n",
      "Delicatessen: [0.01484041 0.0777204  0.05652963]\n"
     ]
    }
   ],
   "source": [
    "print(\"1: Logistic Regression\")\n",
    "print(\"Point Estimates\")\n",
    "print(\"MLE:         \", beta_mle)\n",
    "print(\"By-hand:     \", beta_mest)\n",
    "print(\"Delicatessen:\", beta_deli)\n",
    "\n",
    "print(\"Variance Estimates\")\n",
    "print(\"MLE:         \", sigma_mle)\n",
    "print(\"By-hand:     \", sigma_mest)\n",
    "print(\"Delicatessen:\", sigma_deli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ccc684",
   "metadata": {},
   "source": [
    "# Example 2: Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b599362",
   "metadata": {},
   "source": [
    "## Example 2a: Standardization by g-computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13b94509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copies of data with policies applied\n",
    "d1 = d.copy()\n",
    "d1['X'] = 1\n",
    "d0 = d.copy()\n",
    "d0['X'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c670aa",
   "metadata": {},
   "source": [
    "### Using `delicatessen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6370cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(theta):\n",
    "    # Dividing parameters into corresponding parts and labels from slides\n",
    "    beta = theta[0:3]                     # Logistic model coefficients\n",
    "    mu1, mu0 = theta[3], theta[4]         # Causal risks\n",
    "    delta1, delta2 = theta[5], theta[6]   # Causal contrasts\n",
    "\n",
    "    # Using built-in regression model functionality from delicatessen\n",
    "    ee_logit = ee_regression(theta=beta,\n",
    "                             y=d['Y'],\n",
    "                             X=d[['intercept', 'X', 'W']],\n",
    "                             model='logistic')\n",
    "\n",
    "    # Transforming logistic model coefficients into causal parameters\n",
    "    y1_hat = inverse_logit(np.dot(d1[['intercept', 'X', 'W']], beta))  # Prediction under a=1\n",
    "    y0_hat = inverse_logit(np.dot(d0[['intercept', 'X', 'W']], beta))  # Prediction under a=0\n",
    "    # Estimating function for causal risk under a=1\n",
    "    ee_r1 = y1_hat - mu1\n",
    "    # Estimating function for causal risk under a=0\n",
    "    ee_r0 = y0_hat - mu0\n",
    "    # Estimating function for causal risk difference\n",
    "    ee_rd = np.ones(d.shape[0])*((mu1 - mu0) - delta1)\n",
    "    # Estimating function for causal risk ratio\n",
    "    ee_rr = np.ones(d.shape[0])*(np.log(mu1 / mu0) - delta2)\n",
    "\n",
    "    # Returning stacked estimating functions in order of parameters\n",
    "    return np.vstack([ee_logit,   # EF of logistic model\n",
    "                      ee_r1,      # EF of causal risk a=1\n",
    "                      ee_r0,      # EF of causal risk a=0\n",
    "                      ee_rd,      # EF of causal risk difference\n",
    "                      ee_rr])     # EF of causal log risk ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4eea8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mestr = MEstimator(psi, init=[0, 0, 0, 0.5, 0.5, 0, 0])\n",
    "mestr.estimate(solver='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bccea801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2a: Causal parameters -- g-computation\n",
      "Risk 1:          0.154\n",
      "95% CI:          [0.089 0.22 ]\n",
      "Risk 0:          0.14\n",
      "95% CI:          [0.114 0.165]\n",
      "Risk Difference: 0.015\n",
      "95% CI:          [-0.055  0.085]\n",
      "Risk Ratio:      1.106\n",
      "95% CI:          [0.697 1.756]\n"
     ]
    }
   ],
   "source": [
    "print(\"2a: Causal parameters -- g-computation\")\n",
    "print(\"Risk 1:         \", np.round(mestr.theta[3], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[3, :], 3))\n",
    "print(\"Risk 0:         \", np.round(mestr.theta[4], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[4, :], 3))\n",
    "print(\"Risk Difference:\", np.round(mestr.theta[5], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[5, :], 3))\n",
    "print(\"Risk Ratio:     \", np.round(np.exp(mestr.theta[6]), 3))\n",
    "print(\"95% CI:         \", np.round(np.exp(mestr.confidence_intervals()[6, :]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448dab37",
   "metadata": {},
   "source": [
    "## Example 2b: Standardization by IPW\n",
    "\n",
    "### Using `delicatessen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e63e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(theta):\n",
    "    # Dividing parameters into corresponding parts and labels from slides\n",
    "    alpha = theta[0:2]                    # Logistic model coefficients\n",
    "    mu1, mu0 = theta[2], theta[3]         # Causal risks\n",
    "    delta1, delta2 = theta[4], theta[5]   # Causal contrasts\n",
    "\n",
    "    # Using built-in regression model functionality from delicatessen\n",
    "    ee_logit = ee_regression(theta=alpha,\n",
    "                             y=d['X'],\n",
    "                             X=d[['intercept', 'W']],\n",
    "                             model='logistic')\n",
    "\n",
    "    # Transforming logistic model coefficients into causal parameters\n",
    "    pscore = inverse_logit(np.dot(d1[['intercept', 'W']], alpha))  # Propensity score\n",
    "    wt = d['X']/pscore + (1-d['X'])/(1-pscore)                     # Corresponding weights\n",
    "    # Estimating function for causal risk under a=1\n",
    "    ee_r1 = d['X']*d['Y']*wt - mu1\n",
    "    # Estimating function for causal risk under a=0\n",
    "    ee_r0 = (1-d['X'])*d['Y']*wt - mu0\n",
    "    # Estimating function for causal risk difference\n",
    "    ee_rd = np.ones(d.shape[0])*((mu1 - mu0) - delta1)\n",
    "    # Estimating function for causal risk ratio\n",
    "    ee_rr = np.ones(d.shape[0])*(np.log(mu1 / mu0) - delta2)\n",
    "\n",
    "    # Returning stacked estimating functions in order of parameters\n",
    "    return np.vstack([ee_logit,   # EF of logistic model\n",
    "                      ee_r1,      # EF of causal risk a=1\n",
    "                      ee_r0,      # EF of causal risk a=0\n",
    "                      ee_rd,      # EF of causal risk difference\n",
    "                      ee_rr])     # EF of causal log risk ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d050716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mestr = MEstimator(psi, init=[0, 0, 0.5, 0.5, 0, 0])\n",
    "mestr.estimate(solver='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "865a10e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2b: Causal parameters -- IPW\n",
      "Risk 1:          0.153\n",
      "95% CI:          [0.088 0.219]\n",
      "Risk 0:          0.14\n",
      "95% CI:          [0.114 0.165]\n",
      "Risk Difference: 0.014\n",
      "95% CI:          [-0.057  0.084]\n",
      "Risk Ratio:      1.098\n",
      "95% CI:          [0.69  1.747]\n"
     ]
    }
   ],
   "source": [
    "print(\"2b: Causal parameters -- IPW\")\n",
    "print(\"Risk 1:         \", np.round(mestr.theta[2], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[2, :], 3))\n",
    "print(\"Risk 0:         \", np.round(mestr.theta[3], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[3, :], 3))\n",
    "print(\"Risk Difference:\", np.round(mestr.theta[4], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[4, :], 3))\n",
    "print(\"Risk Ratio:     \", np.round(np.exp(mestr.theta[5]), 3))\n",
    "print(\"95% CI:         \", np.round(np.exp(mestr.confidence_intervals()[5, :]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167b3c4",
   "metadata": {},
   "source": [
    "## Example 3: Transport to External Target\n",
    "\n",
    "Loading data from target population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f1f5e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Population Data\n",
    "d_target = pd.DataFrame()\n",
    "d_target['X'] = [0, 0, 1, 1]\n",
    "d_target['W'] = [0, 1, 0, 1]\n",
    "d_target['n'] = [300, 300, 300, 100]\n",
    "d_target['zapps'] = 0\n",
    "d_target['intercept'] = 1\n",
    "d_target = pd.DataFrame(np.repeat(d_target.values, d_target['n'], axis=0),  # Expanding compact data frame\n",
    "                        columns=d_target.columns)                           # ... keeping column names\n",
    "d_target = d_target[['intercept', 'X', 'W', 'zapps']].copy()                # Dropping the n column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b08fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding population indicator to ZAPPS\n",
    "d['zapps'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e86fa0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking data together\n",
    "df = pd.concat([d, d_target], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6e37c0",
   "metadata": {},
   "source": [
    "`delicatessen` does not natively handle missing data (this was a design decision). Here, we will fill the `nan` with a generic missing value (we make the missing value obvious, -999). As our estimating equation contributions will be restricted to observations where values are not missing, this placeholder value does not matter. However, we choose an extreme value to throw off the estimating equations if we were to accidentally allow the missing values to contribute. \n",
    "\n",
    "See the `delicatessen` documentation for further details on how to handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aceb867",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_no_nan = np.nan_to_num(df['Y'], nan=-999)\n",
    "s = np.asarray(df['zapps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a5724",
   "metadata": {},
   "source": [
    "## Example 3a: g-computation\n",
    "\n",
    "### Using `delicatessen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8d92261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(theta):\n",
    "    # Dividing parameters into corresponding parts and labels from slides\n",
    "    beta = theta[0:3]   # Logistic model coefficients\n",
    "    mu = theta[3]       # Risk\n",
    "\n",
    "    # Using built-in regression model functionality from delicatessen\n",
    "    ee_logit = ee_regression(theta=beta,\n",
    "                             y=y_no_nan,\n",
    "                             X=df[['intercept', 'X', 'W']],\n",
    "                             model='logistic')\n",
    "    ee_logit = ee_logit * s  # Restricting contributions to ZAPPS\n",
    "\n",
    "    # Transforming logistic model coefficients into causal parameters\n",
    "    y_hat = inverse_logit(np.dot(df[['intercept', 'X', 'W']], beta))  # Predictions\n",
    "    # Estimating function for causal risk under a=1\n",
    "    ee_r1 = (1-s) * (y_hat - mu)\n",
    "\n",
    "    # Returning stacked estimating functions in order of parameters\n",
    "    return np.vstack([ee_logit,   # EF of logistic model\n",
    "                      ee_r1])     # EF of risk in target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3ba99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mestr = MEstimator(psi, init=[0, 0, 0, 0.5])\n",
    "mestr.estimate(solver='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa0eba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3a: Transport -- g-computation\n",
      "Risk:    0.155\n",
      "95% CI:  [0.121 0.19 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"3a: Transport -- g-computation\")\n",
    "print(\"Risk:   \", np.round(mestr.theta[-1], 3))\n",
    "print(\"95% CI: \", np.round(mestr.confidence_intervals()[-1, :], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab53f83c",
   "metadata": {},
   "source": [
    "## Example 3b: inverse odds of sampling weights\n",
    "\n",
    "### Using `delicatessen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39a3c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(theta):\n",
    "    # Dividing parameters into corresponding parts and labels from slides\n",
    "    alpha = theta[0:3]   # Logistic model coefficients\n",
    "    mu = theta[3]       # Risk\n",
    "\n",
    "    # Using built-in regression model functionality from delicatessen\n",
    "    ee_logit = ee_regression(theta=alpha,\n",
    "                             y=s,\n",
    "                             X=df[['intercept', 'X', 'W']],\n",
    "                             model='logistic')\n",
    "\n",
    "    # Computing IOSW\n",
    "    pi = inverse_logit(np.dot(df[['intercept', 'X', 'W']], alpha))  # Probablility score\n",
    "    wt = (1-pi)/pi                                                  # Corresponding weights\n",
    "\n",
    "    # Estimating function for causal risk under a=1\n",
    "    ee_r1 = s * wt * (y_no_nan - mu)\n",
    "\n",
    "    # Returning stacked estimating functions in order of parameters\n",
    "    return np.vstack([ee_logit,   # EF of logistic model\n",
    "                      ee_r1])     # EF of risk in target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6a9b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "mestr = MEstimator(psi, init=[0, 0, 0, 0.5])\n",
    "mestr.estimate(solver='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93917cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3b: Transport -- IOSW\n",
      "Risk:          0.155\n",
      "95% CI:          [0.115 0.195]\n"
     ]
    }
   ],
   "source": [
    "print(\"3b: Transport -- IOSW\")\n",
    "print(\"Risk:         \", np.round(mestr.theta[-1], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[-1, :], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43c6bf",
   "metadata": {},
   "source": [
    "END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
